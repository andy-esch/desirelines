#!/bin/bash
set -e

# Setup script for local testing environment with live Strava API and BigQuery
# This script creates the necessary BigQuery resources for ad hoc testing

echo "ðŸš€ Setting up local testing environment..."

# Check required environment variables
check_env_var() {
    if [ -z "${!1}" ]; then
        echo "âŒ Error: $1 environment variable is required"
        exit 1
    fi
}

echo "ðŸ“‹ Checking environment variables..."
check_env_var "GCP_PROJECT_ID"
check_env_var "STRAVA_CLIENT_ID"
check_env_var "STRAVA_CLIENT_SECRET"
check_env_var "STRAVA_REFRESH_TOKEN"

# Set defaults for local testing
LOCAL_DATASET="${GCP_BIGQUERY_DATASET:-local_testing}"
LOCAL_TABLE="activities_adhoc"

echo "ðŸ”§ Configuration:"
echo "  Project ID: $GCP_PROJECT_ID"
echo "  Dataset: $LOCAL_DATASET"
echo "  Table: $LOCAL_TABLE"

# Authenticate with gcloud if not already authenticated
if ! gcloud auth list --filter=status:ACTIVE --format="value(account)" | grep -q .; then
    echo "ðŸ” Authenticating with Google Cloud..."
    gcloud auth login
fi

# Set the project
echo "ðŸ“ Setting GCP project..."
gcloud config set project $GCP_PROJECT_ID

# Create dataset if it doesn't exist
echo "ðŸ“Š Creating BigQuery dataset (if needed)..."
if ! bq show $GCP_PROJECT_ID:$LOCAL_DATASET >/dev/null 2>&1; then
    echo "  Creating dataset: $LOCAL_DATASET"
    bq mk --dataset --location=US $GCP_PROJECT_ID:$LOCAL_DATASET
else
    echo "  Dataset already exists: $LOCAL_DATASET"
fi

# Generate and create table schema
echo "ðŸ—ï¸  Creating BigQuery table..."
SCHEMA_CLI=$(uv run infrastructure/schema_to_bq.py activities)

# Create or update the table
echo "  Creating table: $LOCAL_TABLE"
bq mk --table --replace \
    --time_partitioning_field=start_date \
    --time_partitioning_type=DAY \
    --description="Ad hoc testing table for Strava activity data" \
    $GCP_PROJECT_ID:$LOCAL_DATASET.$LOCAL_TABLE \
    "$SCHEMA_CLI"

echo "âœ… BigQuery table created successfully!"

# Update .env with local testing values
echo "ðŸ“„ Updating .env file for local testing..."
cat > .env << EOF
# Local Testing Environment Configuration
# Generated by scripts/setup_local_testing.sh

# GCP Configuration
GCP_PROJECT_ID=$GCP_PROJECT_ID
GCP_BIGQUERY_DATASET=$LOCAL_DATASET
GCP_BUCKET_NAME=${GCP_BUCKET_NAME:-desire-lines-local-testing}
GCP_PUBSUB_TOPIC=strava-webhook-events

# Strava API Configuration (Live)
STRAVA_CLIENT_ID=$STRAVA_CLIENT_ID
STRAVA_CLIENT_SECRET=$STRAVA_CLIENT_SECRET
STRAVA_REFRESH_TOKEN=$STRAVA_REFRESH_TOKEN

# Webhook Configuration (for testing dispatcher)
STRAVA_WEBHOOK_VERIFY_TOKEN=${STRAVA_WEBHOOK_VERIFY_TOKEN:-local-testing-token}
STRAVA_WEBHOOK_SUBSCRIPTION_ID=${STRAVA_WEBHOOK_SUBSCRIPTION_ID:-999999}

# Logging
LOG_LEVEL=INFO
EOF

echo "âœ… Local testing environment setup complete!"
echo ""
echo "ðŸŽ¯ Next steps:"
echo "1. Test the Strava API connection:"
echo "   uv run python scripts/test_strava_connection.py"
echo ""
echo "2. Test writing to BigQuery:"
echo "   uv run python scripts/test_bq_write.py"
echo ""
echo "3. Run end-to-end test:"
echo "   uv run python scripts/test_end_to_end.py"
echo ""
echo "ðŸ“Š View your data in BigQuery:"
echo "   https://console.cloud.google.com/bigquery?project=$GCP_PROJECT_ID&ws=!1m4!1m3!3m2!1s$GCP_PROJECT_ID!2s$LOCAL_DATASET"
